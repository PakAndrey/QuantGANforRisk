{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QuantGAN for Risk Management\n",
    "\n",
    "Here, we apply QuantGAN to calculate potential future loss from a purchase of a stock.\n",
    "To find this, we calculate the differences between the purchase price of the stock and a q-percentile of a distribution of the stock price on each business date until a specified future date. As a measure of potential futures loss we take the maximum loss across the time interval.\n",
    "\n",
    "To find the distributions of the future stock price, we first train the QuantGAN to obtain the stock price dynamics and then simulate the paths. The main idea here is instead of long full training of the model, we are going to use Transfer Learning principle and load the generator to the pretrained model (which was fully trained on 10 years of S&P500 price). After that, we train model only for a small number of batches on the historical price of the given stock going up to 2 years back (which takes considerably less time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from preprocess.acf import *\n",
    "from preprocess.gaussianize import *\n",
    "\n",
    "from tensorflow.random import normal\n",
    "from tensorflow.keras.models import load_model\n",
    "import yfinance as yf\n",
    "from model.tf_gan import GAN\n",
    "from model.tf_tcn import *\n",
    "\n",
    "generator = load_model(f\"/Users/andreypak/Downloads/temporalCN-main/trained/trained_generator_SP500_daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateVaR(ticker, purchaseDate, NDays, NSim=500, q=0.05, n_batches = 10):\n",
    "    purchaseDate = datetime.strptime(purchaseDate,'%Y-%m-%d')\n",
    "    if not bool(len(pd.bdate_range(purchaseDate, purchaseDate))):\n",
    "        return print(f\"{purchaseDate} is not a business date!\")\n",
    "\n",
    "    df = yf.download(ticker, start=purchaseDate - timedelta(days=730) , end=purchaseDate+timedelta(days=1))\n",
    "    ts = df['Adj Close']\n",
    "    if len(ts)<500:\n",
    "        return print(\"Price history is not long enough!\")\n",
    "\n",
    "    receptive_field_size = 127\n",
    "    fixed_filters = 80\n",
    "    block_size = 2\n",
    "    batch_size = 64\n",
    "\n",
    "    standardScaler1 = StandardScaler()\n",
    "    standardScaler2 = StandardScaler()\n",
    "    gaussianize = Gaussianize()\n",
    "\n",
    "    log_returns = np.log(ts/ts.shift(1))[1:].to_numpy().reshape(-1, 1)\n",
    "    log_returns_preprocessed = standardScaler2.fit_transform(gaussianize.fit_transform(standardScaler1.fit_transform(log_returns)))\n",
    "\n",
    "\n",
    "    discriminator = TCN([receptive_field_size, 1],fixed_filters=100)\n",
    "\n",
    "    gan = GAN(discriminator, generator, 2 * receptive_field_size - 1, lr_d=1e-4, lr_g=3e-5)\n",
    "    log_returns_rolled = rolling_window(log_returns_preprocessed, receptive_field_size)\n",
    "    data = np.expand_dims(np.moveaxis(log_returns_rolled, 0,1), 1).astype('float32')\n",
    "    gan.train(data, batch_size, n_batches)\n",
    "\n",
    "\n",
    "    noise = normal([NSim, 1, NDays+receptive_field_size-1, 3])\n",
    "    y = generator(noise).numpy().squeeze()\n",
    "    y = (y - y.mean(axis=0))/y.std(axis=0)\n",
    "    y = standardScaler2.inverse_transform(y)\n",
    "    y = np.array([gaussianize.inverse_transform(np.expand_dims(x, 1)) for x in y]).squeeze()\n",
    "    y = standardScaler1.inverse_transform(y)\n",
    "\n",
    "    S0 = df.loc[df.index == purchaseDate.strftime('%Y-%m-%d')][\"Adj Close\"].to_numpy().squeeze()\n",
    "    S = np.exp(np.cumsum(np.insert(y, 0, np.ones(NSim)*np.log(S0), axis=1), axis=1))\n",
    "    Q = np.quantile(S, q, axis=0)\n",
    "    L = S0-Q\n",
    "\n",
    "    \n",
    "    print(f\"The purchase price of stock is {S0}.\")\n",
    "    print(f\"There is {q} probability that the loss on {ticker} will exceed {max(L)} if bought on {purchaseDate} and hold for {NDays}-day (business) period.\")\n",
    "    plt.plot(S.T, alpha=0.75)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Guide\n",
    "User only needs to know:\n",
    "- ticker name, \n",
    "- date of stock purchase,\n",
    "- the horizon in business days for which user is planning to hold the stock.\n",
    "\n",
    "optional:\n",
    "- number of simulation paths,\n",
    "- loss percentile,\n",
    "- number of batches.\n",
    "\n",
    "The output: \n",
    "- Stock purchase price,\n",
    "- The potential future loss.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Price history is not long enough!\n"
     ]
    }
   ],
   "source": [
    "CalculateVaR(\"CPNG\", \"2023-02-08\", 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('quantGAN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "878d3bd72b75821762f64af5d361db39c8009f7d7d2bf84dfb1a524f31737713"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
